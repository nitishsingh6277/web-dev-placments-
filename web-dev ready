Q1. Cookies are used for session management and have a limited size with options for expiration. 
Local Storage and Session Storage are both used for client-side data storage,
but Local Storage persists data beyond the browser session,
while Session Storage is temporary and limited to the current session.

Q2.The for loop quickly iterates from 0 to 4 and schedules five setTimeout callbacks with a delay of 100 milliseconds.
After the for loop finishes, the current value of i is 5.
output: 
5
5
5
5
5
to since var keyword doesnt set the values of i for each callbacks .. we can use 
for (let i = 0; i < 5; i++) {
  setTimeout(() => console.log(i), 100);
}
we can use let keyword to have each binding new everytime of the loop to get ..output
0 
1
2
3
4
Q3.
Sharding in MongoDB is a technique used to horizontally partition data across multiple servers or machines to distribute the load 
and improve scalability. It allows MongoDB databases to handle large amounts of data and high write/read throughput by distributing
the data across multiple nodes, also known as shards.
there are various types of sharding used in mongodb 
Range-based sharding involves choosing a shard key that defines a range of values for the documents.
MongoDB will then distribute the data across shards based on the range of shard key values.
The range can be defined based on ascending or descending order of shard key values.
For example, if you use a timestamp as the shard key, the data will be distributed
across shards based on the range of timestamps.
Hashed Sharding (Sharding with a Custom Shard Key):

Hashed sharding involves using a custom shard key that is hashed to determine the shard where each document should be stored.
Instead of using a range of values, the hashed value of the shard key is used to distribute data across the shards.
With hashed sharding, data distribution is more random and evenly distributed across the shards, avoiding hotspots that 
can occur with range-based sharding. However, it makes range-based queries on the shard key less efficient.
Hashed sharding is particularly useful when you don't have a natural shard key that provides a good distribution
of data or when you want a more even distribution.

Q4.
Promise chaining is a technique in JavaScript used to perform asynchronous operations in a sequential
and more readable manner. It allows you to chain multiple asynchronous operations together, 
where the output of one operation is used as the input for the next operation. This helps avoid "callback hell" and makes the code easier to understand.
// Using Promise chaining to fetch user data

fetchUserId()
  .then((userId) => fetchUserProfile(userId)) // Using the user ID to fetch the user profile
  .then((userProfile) => fetchUserPosts(userProfile)) // Using the user profile to fetch user posts
  .then((posts) => console.log("User Posts:", posts)) // Displaying the fetched posts
  .catch((error) => console.error("Error:", error)); // Handling any errors that may occur

Q5. 
Higher-Order Components (HOC) is an advanced pattern in React that allows you to enhance the behavior of components
by wrapping them with a function. HOCs are not part of the React API but are a pattern created by developers
to add cross-cutting concerns or share functionality between components. HOCs themselves are functions 
that take a component as an argument and return a new component with added props or behavior.

Here's how Higher-Order Components work:

Input Component: You have a base or input component that you want to enhance with additional functionality or data.

Higher-Order Component: You create a function (HOC) that takes the input component as an argument
and returns a new component with added props or behavior.

Enhanced Component: The returned component from the HOC is an enhanced version of the input
component with additional functionality or data.

Reusability: The HOC can be reused with different input components to provide similar enhancements.


Q6.
Callback hell, also known as the pyramid of doom, is a situation that arises 
in asynchronous programming when multiple nested callbacks are used. It occurs when one asynchronous
operation depends on the result of another asynchronous operation, and this dependency continues in a chain of callbacks.
asyncOperation1(function (result1) {
  asyncOperation2(result1, function (result2) {
    asyncOperation3(result2, function (result3) {
      // More nested callbacks...
    });
  });
});
solutions.. 
Using named functions..

function handleResult1(result1) {
  asyncOperation2(result1, handleResult2);
}

function handleResult2(result2) {
  asyncOperation3(result2, handleResult3);
}

function handleResult3(result3) {
  // Handle result3
}

asyncOperation1(handleResult1);
...
promises..
asyncOperation1()
  .then((result1) => asyncOperation2(result1))
  .then((result2) => asyncOperation3(result2))
  .then((result3) => {
    // Handle result3
  })
  .catch((error) => {
    // Handle errors
  });

usingg async/await...

async function fetchData() {
  try {
    const result1 = await asyncOperation1();
    const result2 = await asyncOperation2(result1);
    const result3 = await asyncOperation3(result2);
    // Handle result3
  } catch (error) {
    // Handle errors
  }
}

fetchData();

Q7..
const arr = [1, 2, 3, 4, 5];

const reversedArr = arr.reduce((accumulator, currentValue) => {
  return [currentValue, ...accumulator];
}, []);

console.log(reversedArr); // Output: [5, 4, 3, 2, 1]

we initialize an empty array [] as the initial value for the accumulator in the reduce() method. Then, for each element in the original array arr, 
we create a new array with the current element at the beginning ([currentValue, ...accumulator]) and assign it to the accumulator. 
This way, the elements are added in reverse order, resulting in the reversed array.
Q8..
output: 1 4 3 2

first synchronus lines like 1 and 4will be printed andthen settimeout calls with asynchronous operations.. since delay of 0 is non-blocking
async so next line 4 will be printed then async like 3 and then after 1000 milliseconds 2 will be printed..

Q9.
output:
array 1: length=5 last=j,o,n,e,s
array 2: length=5 last=j,o,n,e,s

Q10.
output:
1 4 3 2
first sync calls then event loop will put async in callback queues..

Q11.
code has a minor issue. It doesn't provide an initial value for the accumulator 
in the reduce function. Let's fix that and explain the output.
const numbers = [1, 2, 3, 4, 5];

const result = numbers.reduce((acc, num) => {
  if (num % 2 === 0) {
    acc.evens.push(num);
  } else {
    acc.odds.push(num);
  }
  return acc;
}, { odds: [], evens: [] });

console.log(result);
output:

{ odds: [1, 3, 5], evens: [2, 4] }



